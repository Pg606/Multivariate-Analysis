---
title: "Salary Project"
author: "pg606@scarletmail.rutgers.edu"
date: "2024-04-29"
output: html_document
---

```{r }
library(ggplot2)
library(corrplot)
library(factoextra)
library(psych)
library(NbClust)
library(magrittr)
library(tidyr)
library(reshape2)
library(MASS)
library(memisc)
library(ROCR)
library(dplyr)
library(klaR)
library(caTools)
library(pROC)
library(caret)



sc_dataset <- read.csv("/Users/Prateekg/Documents/MVA/Salary_multiple_regression.csv", row.names=1)
str(sc_dataset)
correlation_matrix <- cor(sc_dataset[,10:15])
correlation_matrix

```


```{r }
ggplot(melt(correlation_matrix), aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 10, hjust = 1)) +
  coord_fixed()

```


```{r }
#PCA

sc_dataset_pca <- prcomp(sc_dataset[,10:15],scale=TRUE) 
sc_dataset_pca

summary(sc_dataset_pca)

fviz_eig(sc_dataset_pca, addlabels = TRUE)

```



```{r }
fviz_pca_var(sc_dataset_pca,col.var = "cos2",
             gradient.cols = c("#FFCC00", "#CC9933", "#660033", "#330033"),
             repel = TRUE)

```



```{r }
#EFA

fit.pc <- principal(sc_dataset[,10:15], nfactors=3, rotate="varimax") 
fit.pc

fa.diagram(fit.pc) 

vss(sc_dataset[,10:15])

```


```{r }
#Clustering

efa_data <- as.data.frame(fit.pc$scores)
efa_data


matstd_sm <- scale(efa_data)

res.nbclust <- matstd_sm %>% scale() %>% NbClust(distance = "euclidean", min.nc = 2, max.nc = 6, method = "complete", index ="all") 

km.res <- kmeans(matstd_sm, 5, nstart = 10)

fviz_cluster(km.res, data = matstd_sm,
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal())

dist.sc_dataset <- dist(matstd_sm, method="euclidean")

res.hc <- matstd_sm %>% scale() %>% dist(method = "euclidean") %>%
  hclust(method="ward.D2")

fviz_dend(res.hc, k = 5, # Cut in four groups
          cex = 0.5, # label size
          k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
          color_labels_by_k = TRUE, # color labels by groups
          rect = TRUE # Add rectangle around groups
)
Clustered <- ifelse(km.res$cluster > 1.5, "Low", "High")
Actual <- ifelse(sc_dataset$salaryLevel == 1, "High", "Low")
confusion_mat <- table(Clustered, Actual)
confusion_mat

accuracy <- sum(diag(confusion_mat)) / sum(confusion_mat)
precision <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
recall <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
cat("Accuracy:", round(accuracy, 3), "\n")

```


```{r}

wdbc <- read.csv("/Users/Prateekg/Documents/MVA/Salary_multiple_regression.csv")
features <- c("Category", "Currency", "EmpResidence","ExpLevel", "EmpType", "WorkSetting", "location", "size", "level", "year", "salary", "USD","YearsExperience", "NoOfCompany", "SalaryLevel")
names(wdbc) <- c("Title", "Category", "Currency", "EmpResidence","ExpLevel", "EmpType", "WorkSetting", "location", "size", "level", "year", "salary", "USD", "YearsExperience", "NoOfCompany","SalaryLevel")
wdbc.data <- as.matrix(wdbc[,c(11:15)])
row.names(wdbc.data) <- wdbc$Title
wdbc_raw <- cbind(wdbc.data, as.numeric(as.factor(wdbc$SalaryLevel))-1)
colnames(wdbc_raw)[6] <- "EmpSalaryLevel"
smp_size_raw <- floor(0.70 * nrow(wdbc_raw))
train_ind_raw <- sample(nrow(wdbc_raw), size = smp_size_raw)
train_raw.df <- as.data.frame(wdbc_raw[train_ind_raw, ])
test_raw.df <- as.data.frame(wdbc_raw[-train_ind_raw, ])


```

Now divided the dataset into training and testing data for regression analysis.

We consider the training and testing data with a 70-30 split.

# MULTIPLE REGRESSION :

* Multiple regression is a statistical technique used to understand the relationship between one dependent variable and two or more independent variables. 

* It aims to predict the value of the dependent variable based on the values of the independent variables.
```{r}
# MULTIPLE REGRESSION
#fit <- lm(TroubleInSleep~Instagram + Snapchat + Twitter, data=sc_dataset) 
#x_sm <- cbind(train_ind_raw,train_raw.df[, -9])

fit <- lm( EmpSalaryLevel~ ., data = train_raw.df) 

summary(fit)
coefficients(fit)
residuals(fit)
probabilities_sm2 <- predict(fit, newdata = test_raw.df, type = "response")

predicted_sm2 <- ifelse(probabilities_sm2 > 0.5, "Yes", "No")
actual_sm <- ifelse(test_raw.df$EmpSalaryLevel == 1, "Yes", "No")
confusion_sm2 <- table(predicted_sm2, actual_sm)
confusion_sm2

roc_sm <- roc(test_raw.df$EmpSalaryLevel, probabilities_sm2)
auc_sm <- auc(roc_sm)

ggroc(roc_sm, color = "blue", legacy.axes = TRUE) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "False Positive Rate", y = "True Positive Rate",
       title = paste("ROC Curve (AUC = ", round(auc_sm, 2), ")")) +
  annotate("text", x = 0.5, y = 0.5, label = paste0("AUC = ", round(auc_sm, 2)))

threshold<-0.5
predicted <- predict(fit, newdata = test_raw.df)

predicted_category <- ifelse(predicted > threshold, "High", "Low")

# Convert actual values to binary categories
actual_category <- ifelse(test_raw.df$EmpSalaryLevel == 1, "High", "Low")

# Create a confusion matrix
confusion_mat <- table(predicted_category, actual_category)

# Calculate accuracy
accuracy <- sum(diag(confusion_mat)) / sum(confusion_mat)
accuracy

```

The regression summary shows that we have significant variables that affect the output variable.

The regression summary shows that we have significant variables that affect the output variable.


# LOGISTIC REGRESSION :

* Logistic regression is a statistical method used for binary classification problems. It predicts the probability that a given observation belongs to one of two classes.
* It models the relationship between a binary dependent variable and one or more independent variables.

We can now check how the logistic regression-

```{r}
# Logistic Regression

logistic_sm <- glm(EmpSalaryLevel ~ ., data = train_raw.df, family = 'binomial')
summary(logistic_sm)

predicted.data <- data.frame(probability.of.hd=logistic_sm$fitted.values,EmpSalaryLevel=train_raw.df$EmpSalaryLevel)
predicted.data <- predicted.data[order(predicted.data$probability.of.hd, decreasing=FALSE),]
predicted.data$rank <- 1:nrow(predicted.data)

ggplot(data=predicted.data, aes(x=rank, y=probability.of.hd)) +
  geom_point(aes(color=EmpSalaryLevel), alpha=1, shape=4, stroke=2) +
  xlab("Index") +
  ylab("Predicted ")
probabilities_sm2 <- predict(logistic_sm, newdata = test_raw.df, type = "response")

predicted_sm2 <- ifelse(probabilities_sm2 > 0.5, "High", "Low")
actual_sm <- ifelse(test_raw.df$EmpSalaryLevel == 1, "High", "Low")
confusion_sm2 <- table(predicted_sm2, actual_sm)
confusion_sm2
accuracy2 <- sum(diag(confusion_sm2)) / sum(confusion_sm2)
precision2 <- confusion_sm2[2, 2] / sum(confusion_sm2[, 2])
recall2 <- confusion_sm2[2, 2] / sum(confusion_sm2[2, ])
cat("Accuracy:", round(accuracy2, 3), "\n")
cat("Precision:", round(precision2, 3), "\n")
cat("Recall:", round(recall2, 3), "\n")
probabilities <- predict(logistic_sm, newdata = test_raw.df, type = "response")

roc_sm <- roc(test_raw.df$EmpSalaryLevel, probabilities_sm2)
auc_sm <- auc(roc_sm)

ggroc(roc_sm, color = "blue", legacy.axes = TRUE) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "False Positive Rate", y = "True Positive Rate",
       title = paste("ROC Curve (AUC = ", round(auc_sm, 2), ")")) +
  annotate("text", x = 0.5, y = 0.5, label = paste0("AUC = ", round(auc_sm, 2)))
```

These visualizations provide valuable insights into the logistic regression model's performance by showcasing Accuracy and ROC Curve of the model.



# DISCRIMINANT :

* Discriminant analysis is a statistical method used for classification tasks that involve identifying which category or group a new observation belongs to based on one or more predictor variables (features).


```{r }
wdbc_raw.lda <- lda(formula = train_raw.df$EmpSalaryLevel ~ ., data = train_raw.df)
wdbc_raw.lda
summary(wdbc_raw.lda)
plot(wdbc_raw.lda)
predictions <- predict(wdbc_raw.lda, newdata = test_raw.df)
predicted_classes <- predictions$class
accuracy2 <- mean(predicted_classes == test_raw.df$EmpSalaryLevel)
accuracy2
wdbc_raw.lda.predict_train <- predict(wdbc_raw.lda, newdata = train_raw.df)
y<-wdbc_raw.lda.predict_train$class
wdbc_raw.lda.predict_train$x
table(y,train_raw.df$EmpSalaryLevel)
wdbc_raw.lda.predict_test <- predict(wdbc_raw.lda, newdata = test_raw.df)
y<-wdbc_raw.lda.predict_test$class
wdbc_raw.lda.predict_test$x
table(y,test_raw.df$EmpSalaryLevel)
wdbc_raw.lda.predict.posteriors <- as.data.frame(wdbc_raw.lda.predict_test$posterior)
pred <- prediction(wdbc_raw.lda.predict.posteriors[,2], test_raw.df$EmpSalaryLevel)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values
plot(roc.perf)
abline(a=0, b= 1)
text(x = .25, y = .65 ,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
plot(wdbc_raw.lda, col = as.integer(train_raw.df$EmpSalaryLevel))




```